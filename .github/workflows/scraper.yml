name: Run My Scraper

on:
  push:
    branches: [ "main" ]
  schedule:
    - cron: "*/15 * * * *"
  workflow_dispatch:

jobs:
  run-scraper:
    runs-on: ubuntu-latest
    env:
      TZ: UTC
    steps:
      - name: Check out repo
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11.5'

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Install Playwright Browsers
        run: playwright install chromium

      - name: Configure ENV
        run: |
          echo "DB_USER=${{ secrets.DB_USER }}" >> $GITHUB_ENV
          echo "DB_PASSWORD=${{ secrets.DB_PASSWORD }}" >> $GITHUB_ENV
          echo "DB_HOST=${{ secrets.DB_HOST }}" >> $GITHUB_ENV
          echo "DB_PORT=${{ secrets.DB_PORT }}" >> $GITHUB_ENV
          echo "DB_NAME=${{ secrets.DB_NAME }}" >> $GITHUB_ENV

      - name: Run the main script
        run: python -m scraper.main
